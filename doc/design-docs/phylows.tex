\documentclass[10pt]{article}
%imports extra math symbols
\usepackage{amssymb}
%used for doublespace text
\usepackage{setspace}
\usepackage{listings}
\usepackage{url}
% uncomment the next line to use graphics
%\usepackage{graphicx}
%shortnames for common commands
\newcommand{\BD}{\begin{doublespace}}
\newcommand{\ED}{\end{doublespace}}
\newcommand{\BE}{\begin{enumerate}}
\newcommand{\EE}{\end{enumerate}}
\newcommand{\BI}{\begin{itemize}}
\newcommand{\EI}{\end{itemize}}
\newcommand{\BT}{\begin{tabular}}
\newcommand{\ET}{\end{tabular}}
\newcommand{\BV}{\begin{verbatim}}
\newcommand{\EV}{\end{verbatim}}
\newcommand{\BM}{\begin{displaymath}}
\newcommand{\EM}{\end{displaymath}}
\newcommand{\BC}{\begin{center}}
\newcommand{\EC}{\end{center}}
\newcommand{\BFR}{\begin{flushright}}
\newcommand{\EFR}{\end{flushright}}
\newcommand{\BFL}{\begin{flushleft}}
\newcommand{\EFL}{\end{flushleft}}
%Stretches out the page
\setlength{\oddsidemargin}{-0.50in}
\setlength{\evensidemargin}{-0.50in}
\setlength{\textwidth}{7.0in}
\setlength{\topmargin}{0.0in}
\setlength{\textheight}{9.0in}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0ex}
\pagestyle{empty}
%\lstset{language=Prolog, frame=lines}
%Sets title page information
\author{Brandon Chisham, Ben Wright}
\title{Web Service Querying for Phylogenetic Information}
\date{\today}

\begin{document}
%Generates the title page
\maketitle

%uncomment the next line to generate a table of contents
%\tableofcontents
\section{Introduction}

\section{Background}
PhyloWS is a standard for RESTful querying of phylogenetic data. CDAO-Store
implements provides the following querying for matrices, trees conforming to a
variety of criteria, and studies through this interface.

\subsection{Phylogenetics}
%TAKEN FROM CDAO-STORE PAPER BACKGROUND
Phylogenetic trees have gained a central role in modern biology. Trees provide
a systematic structure to organize evolutionary knowledge about diversity of
life. Trees have become fundamental tools for building new knowledge, thanks to
their explanatory and comparative-based predictive capabilities.  Evolutionary
relationships provide clues about processes underlying biodiversity and enable
predictive inferences about future changes in biodiversity (e.g., in response
to climate or anthropogenic changes).  Phylogenies are used with increase
frequency in several fields, e.g., comparative genomics \cite{Ell08}, metagenomics \cite{WE08},
and community ecology \cite{WAMD02}.  The development of novel solutions to enhance the
ability to use phyloinformatics solutions in various areas of biology, have
built on a number of important technologies.

\subsection{CDAO}
%THIS SECTION TAKEN VERBATIM FROM THE CDAO-STORE PAPER
The Comparative Data Analysis Ontology (CDAO) \cite{cdao-evol} provides a formal ontology
for describing phylogenies and their associated character state matrices.  It
was developed as part of the Evolutionary Informatics (EvoInfo) working group,
sponsored by the National Evolutionary Synthesis Center.

The CDAO ontology provides the semantic component of a data representation and
inter-operation stack for phyloinformatics, known as the EvoIO stack \cite{evoio}along
with a data exchange format, called nexml \cite{nexml}, and a phyloinformatics web
services API, known as PhyloWS \cite{phylows}. CDAO forms the base of this stack defining
the semantics for the data represented as nexml files, or otherwise supplied by
services implementing this set of standards.  Figure 1 illustrates the EvoIO
stack.


CDAO is implemented as a formal ontology encoded in OWL. It provides a general
framework for talking about the relationships between taxa, characters, states,
their matrices, and associated phylogenies. The ontology is organized around
four central concepts (see also Figure 2): OTUs, characters, character states,
phylogenetic trees, and transitions. The key concepts and their mutual
relationships within CDAO are illustrated in Figure 3.  A phylogenetic analysis
starts with the identification of a collection of operational taxonomic units
(OTUs), representing the entities being described (e.g., species, genes). Each
OTU is described, in the analysis, by a collection of properties, typically
referred to as characters. In phylogenetic analysis, it is common to collect
the characters and associated character states in a matrix, the character state
matrix, where the rows correspond to the different OTUs and the columns
correspond to the characters.


In evolutionary biology, phylogenetic trees and networks are used to represent
paths of descent-with-modification, capturing the evolutionary process
underlying the considered OTUs.  Since evolution moves forward in time, the
branches of a tree are typically directed. The terminal nodes are anchored in
the present, as they represent observations or measurements made on existing
organisms. The internal nodes represent common ancestors, with the deepest node
as the root node of the tree. The restriction that each node has at most one
immediate ancestor reflects the assumption that evolutionary lineages, once
separates, do not fuse (e.g., because of the assumption of the biological
species concept based on reproductive isolation). Branching is considered to be
a binary process of splitting by specification (or gene duplication, in the
case of molecular sequences). Even with terminal nodes anchored in the present,
it may be impossible to infer the direction of each internal branch, in which
case the tree may be referred to as an unrooted tree or as a network. Even the
restriction of single parentage maybe occasionally abandoned (e.g., in the case
of lateral transfer or reticulate evolution).


As a general framework, CDAO supplies general classes and relations between
those classes, that can be further specialized to meet the needs of a specific
application|Beak length might be defined as a specialization of CDAO's Standard
character type.

\subsection{CDAO-Store}
%FROM BACKGROUND SECTION OF CDAO-STORE PAPER
The CDAO-Store is a novel portal aimed at facilitating the storage and
retrieval of phylogenetic data. The novelty of CDAO-Store lies in the use of a
semantic-based approach to the storage and querying of data, building on
established ontologies for the semantic annotation of data. This approach
enables us to overcome restrictions imposed by the use of specific data formats
(facilitating interoperation among phylogenetic analysis applications) and
makes it possible to formulate more meaningful domain-specific queries.

%TAKEN FROM IMPLEMENTATION SECTION OF CDAO-STORE PAPER
CDAO-store builds on the EvoIO technology stack to provide a semantic-based
repository of phylogenetic data, accessible through semantic web services and a
domain-specific query language. The CDAO-Store platform is open-source and is
available as a SourceForge project, at sourceforge.net/projects/cdaotools.  The
implementation of CDAO-store is organized in three interconnected modules, as
illustrated in Figure 4: a data importer module, a repository module, and an
exporter module.  For more detail, please refer to the CDAO-Store paper.

\subsection{PhyloWS}
%Taken from BACKGROUND PHYLOWS section of CDAO-STORE PAPER
PhyloWS (Phyloinformatics Web Services API) is a standard for exposing
phylogenetic data as a web service. Web services are tools that can perform
certain tasks via HTTP \cite{WebService}. PhyloWS specifically uses a RESTful
style web service which uses a few well-known operations to relay data
\cite{PhyloWSWiki}  \cite{Fielding02principleddesign}. This works in a similar
way as GET or POST for HTTP \cite{Fielding02principleddesign}.  All PhyloWS
URI's begin with /phylows/ as the standard delimiter. Then based on the
phylogenetic information being queried a data structure will be given, such as
taxon, tree, or study.  This is followed by any specific identifiers needed for
the query.
For example, http://purl.org/phylo/treebase/phylows/tree/TB2:Tr3099?format=rdf
is a way to access information from TreeBASE using PhyloWS. When this URL is
accessed, it returns the tree with the TreeBASE ID equal to 'Tr3099' in RDF
format \cite{treebasePhyloWS}. A specification for PhyloWS can be found at \cite{PhyloWSWiki}.

%TAKEN FROM Results:Web-Tools of CDAO-STORE PAPER
The web tools from CDAO-Store provide a variety of querying and data access
features for both human and programmatic access to data. It allows one to
retrieve data sets by author name, tree identifier, taxon, algorithm, or
method. It also supports computing the minimum spanning clade or the nearest
common ancestor of a set of taxa. It also allows one to list trees conforming
to certain measures. For example, finding all trees larger or smaller than a
given size. 

Our PhyloWS implementation is the basis for all the data access features of
CDAO-Store. The other web components, and the CDAO-Explorer tool use it to
access data. URI's are divided into three conceptual parts. The address of the
store site, and path prefix \url{http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/phylows}, a
query type (i.e., tree, matrix, msc, nca, or size), and parameter list. The
specific parameters depend on the query type. For example, the msc and nca
query types expect a list of taxon id's separated by `/'. The listing query
takes optional limit and offset parameters to paginate results. The size query
takes a direction (greater, less, or equal), a criteria (node, internal, or
leaf) and a size (a numeral).

\section{How Does the CDAO-Store PhyloWS Interface Work?}
The implementation is broken into 3 layers
  \subsection{Request Manager}
    The request manager takes care of parsing, sanitizing, interpreting request
arguments, and orchestrating  the remaining components.  In practice this is
broken into a set of scripts named according to the following convention
do\_FORMAT\_QUERY-NAME\_query.sh where FORMAT indicates the output format of
the script, and QUERY-NAME indicates the type of query that the script handles.
These scripts are installed outside the web-space for ease of use since
otherwise permission issues would prevent them from being used and also
installable by members of the ``cdao'' group.

     After processing the arguments the handler script invokes the Query
Processing layer, and formats the output from the query processor.

     \paragraph{Anatomy of a Request Manager}
      The structure of a request manager mirrors this layering. First query
variables are extracted from the QUERY\_STRING and/or REQUEST\_URI environment
variables.  Next the query processor is run. For SPARQL queries this is the
do\_query.py script. For prolog queries, several more steps are necessary
including creating several temporary files for the prolog saved state file, as
well as input rules, used to create the saved state. The prolog system then
processes the query and the results are reformatted for the client.
  \subsection{Query Processing}
     \paragraph{Basic Processing} Most queries are processed using the
do\_query.py Phython script. This script uses the RDFlib library to query the
store, and return formatted results based on a query and format string that are
supplied as arguments.
     
 
  \subsection{Output Formatting}
     After query processing results are formatted for output. For most queries
the formatting is largely determined by the format string given to the query
processor, and a query dependent header and footer.  For the tree queries, the
output is filtered through another post processing layer to reorder the results
so that they can be more easily processed by some tools. In this phase, the
node and edge definitions are put into breadth-first order. (they are declared
in the file in an order such that a client reading the file will encounter the
declarations in the same order they would if making a breadth first traversal
of the actual tree being defined).



\section{Query Processing Implementation}
    \paragraph{Prolog} Some queries supported by the store are not processable
with SPARQL alone. These queries generally require features such as
transitivity that are hard or impossible to process given the limits on the
expressibility of these queries. The following queries use Prolog to process
Nearest-Common Ancestor or Minimum Spanning-Clade of a set of Taxa, or the
finding trees by some size criterion. 

      The nearest-common ancestor of a set of taxa is an ancestor of each taxon
in the set, and none of it's descendants are also ancestors of all the taxa in
the set. 
      
       The minimum spanning clade of a set of taxa is the set of nodes that
includes the nearest-common ancestor of all the taxa in the set, and all of its
descendants.

       The size queries provide the most variety, since size depends entirely
on one's choice of metric. CDAO-Store implements the following measures of
size. The number of nodes, the number of internal nodes, the number of leaves,
the radius, or the diameter of a tree. These queries also operate on the entire
collection of trees rather than a particular tree or small small set of trees.
The various count queries are quite efficient since they mostly require looking
at the nodes and only process edge relations to the extent they are needed to
classify a node as a leaf or an internal node, but this check does not require
any recursive varification of relations so it is also quite efficient.

       The radius and diameter queries require finding the shortest and longest
paths across a tree respectively, but this requires checking all the paths, in
all the trees, which ends up being too slow to be usable on the web since
clients will time-out before the request can be full-filled. 

       \paragraph{Pre-processing}
       The nearest common ancestor and minimum spanning clade queries begin
using the sparql layer to generate a set of facts about the tree including its
nodes and edges. The final step in pre-processing is to append a set of rules
for deriving basic relationships between nodes based on edge facts.

       The user's request is then converted into a prolog format query. At this
point addition facts are also dynamically generated. Things such as the rule
for finding nearest common ancestor depend on the size of the set of taxa so
they can not be statically defined. 
       
       Finally the request is compiled into a Prolog stored computation, which
is then run. 

       The results of from the prolog environment are then reformatted for the
user's requested output format and returned to the user.

The repository module provides two core functionalities: storage and querying.
The repository module maintains a triple store, used to maintain all the CDAO
instances created, either through submitted user files or through processing of
Tree-BASE content. The triple store is implemented in Python and uses the
RDFlib5 module to store the RDF serializations of CDAO instances in a
relational database (implemented using a MySQL database).  The repository
modules supports the execution of queries against the triple store. This set of
queries is primarily drawn from the description given by Nakhleh et al. \cite{queries},
that provides a characterization of a relevant set of domain specific queries
that are desirable for any repository of phylogenetic structures. The
repository module supports all the, fully-specified, types of queries
identified in \cite{queries}. This is a diverse set of queries ranging from those that
can be processed using simple syntactic matching requiring little additional
reasoning to complex queries of tree structures. The domain-specific types of
queries are:

\begin{enumerate}
\item Determine all the phylogenies containing a given set of taxa;
\item Determine the relationships among a set of taxa in all phylogenies;
\item Determine the minimum spanning tree/clade for a given set of taxa;
\item Determine all phylogenies constructed using a given inference method;
\item Determine all the phylogenies containing a set number of taxa;
\item Determine all the phylogenies produced by a given tool or author;
\item Determine all phylogenies containing a given characteristic (e.g.,
diameter of the tree, width of the tree);
\item Given a phylogeny P, a measure m, and a quantity q, determine all the
phylogenies that are at distance q from P according to the measure m (e.g., for
the purpose of clustering phylogenies that are "close" to a given tree);
\item Given a model of evolution, determine all the phylogenies that have been
constructed using such model of evolution;
\item Given some measures, return statistics about the measure in the
phylogenies present in the repository (e.g., distribution of tree lengths);
\item Given a type of data and a set of taxa, determine all the phylogenies on
the set of taxa that have been constructed using the specified type of data
(e.g., determine all phylogenies built using morphological data or using DNA
sequences).
\end{enumerate}
To address these different types of queries, the query system is divided into two primary modules:
\begin{itemize}
\item The RDFlib has been linked to a SPARQL \cite{sparql} engine and an OWL reasoner,
Pellet, enabling the execution of standard SPARQL queries to access the data
in the triple store;
\item Other types of queries are beyond the expressive power of the standard
SPARQL query languages. In order to support these, the repository module has
the capability of mapping CDAO tree and network structures, stored in the
triple store, to corresponding representations of trees and networks in Prolog
\cite{prolog}, a popular programming language for knowledge representation and
reasoning. The remaining types of queries are implemented in Prolog.
\end{itemize}

\subsection{Query Implementation}
Questions 1,4,6,and10 can be answered using just SPARQL queries.  Questions
3,5,7,8,and11 have been implemented using Prolog.   For the queries that are
not supported, the primary cause is the lack of a precise specification of the
query, or the data is not currently available. For example, the set of
relationships one might be interested in having returned was not fully
specified in the original article \cite{queries}.  Clearly, the availability of a SPARQL
interface enables the user to submit also arbitrary other queries, as long as
these are expressible as SPARQL queries.
\subsubsection{Basic Structure}

The ground rules used for the Prolog queries are the nodes and edges of all the
trees, formatted as follows:
\begin{verbatim}
node(TreeName, NodeName).
edge(TreeName, EdgeName, Direction, SourceNode, DestinationNode).
\end{verbatim}

For simplicity, the nodes can be checked as internal, root, or leaf node as well:
\begin{verbatim}
leaf( Tree, Node ):- node( Tree, Node ), not(edge(Tree, _, _, Node, _)).
root( Tree, Node ):- node( Tree, Node ), not(edge(Tree,_,_, _,Node )).
internal_node( Tree, Node ):- node( Tree, Node ), edge(Tree,_,Node,_).
\end{verbatim}

\subsubsection{Question 1}
 Determine all the phylogenies containing a given set of taxa.

This query can be implemented in sparql as follows
\begin{verbatim}
PREFIX study: <http://www.cs.nmsu.edu/~bchisham/study.owl#>
PREFIX contact: <http://www.w3.org/2000/10/swap/pim/contact#>
PREFIX foaf: <http://www.mindswap.org/2003/owl/foaf#>

SELECT ?tree WHERE {
    ?tree has_TU TU1.
    .
    .
    .
    ?tree has_TU TUN.
}
\end{verbatim}
However because the original data were imported with the TU's in the name space
of their source files rather than a common name space, the above query is not
our implementation.

With a script we have pre-computed the inverse of the tree to tu relation given
in the source data, and then using xslt we extract the intersection of the
trees that each tu has in common based on this pre-computed result-set.
Ultimately this measure will be replaced as we migrate the existing set of TU
names to be references to NCBI or some other commonly accepted taxonomic
reference.


\subsubsection{Question 2}
Determine the relationships among a set of taxa in all phylogenies.

Not implemented.  The term "relationship" is too ambiguous.

\subsubsection{Question 3}
Determine the minimum spanning tree/clade for a given set of taxa.

\paragraph{Minimum Spanning Tree/Clade}

Clades are merely subsets of nodes in the tree.

\begin{verbatim}
clade( Tree, Node, Member ):- ancestor_of( Tree, Node, Member ).
clade( Tree, Node, Node):- node( Tree, Node ).
clade( Tree, Node ):- setof( Member, clade( Tree, Node, Member ), Members ), write( Members ).
\end{verbatim}

This uses one helper function, \emph{ ancestor\_of/3 }.  This returns true if
Member is a child of Node, or a child of one of Node's children.

\paragraph{Nearest Common Ancestor}

Nca is slightly different from msc and as such, is done seperately.

\subsubsection{Question 4}
Determine all phylogenies constructed using a given inference method;

There are two different 'methods' that can be checked.  One is the algorithm,
the other is by the software used.  Both are implemented using SPARQL.

\begin{verbatim}
PREFIX study: <http://www.cs.nmsu.edu/~bchisham/study.owl#>
PREFIX contact: <http://www.w3.org/2000/10/swap/pim/contact#>
PREFIX foaf: <http://www.mindswap.org/2003/owl/foaf#>
SELECT ?tree
WHERE {
    ?study study:has_analysis ?analysis.
    ?analysis study:has_algorithm '$ALGO' .
    ?analysis study:has_output_tree ?tree .
}
\end{verbatim}

\begin{verbatim}
PREFIX study: <http://www.cs.nmsu.edu/~bchisham/study.owl#>
PREFIX contact: <http://www.w3.org/2000/10/swap/pim/contact#>
PREFIX foaf: <http://www.mindswap.org/2003/owl/foaf#>
SELECT ?tree
WHERE {
    ?study study:has_analysis ?analysis .
    ?analysis study:has_software '$ALGO' .
    ?analysis study:has_output_tree ?tree .
}
\end{verbatim}

Where \emph{\$ALGO} is the variable for the given algorithm/software being checked for.

\subsubsection{Question 5}
 Determine all the phylogenies containing a set number of taxa.

\begin{verbatim}
%Count the number of nodes in a tree
node_count( Tree, Count ):- root( Tree, RootNode ), node_count( Tree, RootNode, Count ).
node_count( Tree, StartNode, Count ):- setof( Node, descendent_of(Tree, Node, StartNode), Nodes ),
					     length( Nodes, Count ).
%Count the leaves in a tree.
leaf_count( Tree, Count ):- leaf_count( Tree, _, Count ).
leaf_count( Tree, _, Count ):- setof( LNode, leaf( Tree, LNode ), Nodes ), length( Nodes, Count ).
%Count the internal nodes in a tree.
internal_count( Tree, Count ):- internal_count( Tree, _, Count ).
internal_count( Tree, _, Count ):- setof( INode, internal_node(Tree,INode), Nodes ), 
				       length( Nodes, Count ).
\end{verbatim}

\subsubsection{Question 6}
 Determine all the phylogenies produced by a given tool or author;

Searching for specific authors has been implemented using SPARQL.

\begin{verbatim}
PREFIX study: <http://www.cs.nmsu.edu/~bchisham/study.owl#>
      PREFIX contact: <http://www.w3.org/2000/10/swap/pim/contact#>
      PREFIX foaf: <http://www.mindswap.org/2003/owl/foaf#>
SELECT ?study
WHERE {
   ?study study:has_author ?authorid.
   ?authorid foaf:last_name '$LAST_NAME'^^<http://www.w3.org/2001/XMLSchema#string>.
   ?authorid foaf:first_name '$FIRST_NAME'^^<http://www.w3.org/2001/XMLSchema#string>.}
\end{verbatim}

Where \emph{\$LAST\_NAME} and \emph{\$FIRST\_NAME} are the last and first name
of the author respectively.  The option to search on just the last name is also
available.

\subsubsection{Question 7}
Determine all phylogenies containing a given characteristic (e.g., diameter of the tree, width of the tree);

This one is separated to asking for width, diameter, or radius.  For the
definitions of what the diameter or radius of a phylogenetic tree is, we treat
the trees as graphs and use the definitions from graph theory for radius and
diameter.
\begin{verbatim}
eccentricity(Tree,Len,Start ):- findall( E, (not(LeafNode == Start),
					leaf(Tree, LeafNode), 
					pathlength(Tree,Start,LeafNode, E)), 
					Lens),
				max_list(Lens, Len).
%Radius = minimum eccentricity of any vertex.
radius( Tree, R ):- findall(Leaf, leaf(Tree, Leaf), Leaves),
	       	      radii(Tree, Leaves, R, _).
radii(Tree, [Leaf | Leaves], Radius, Curr) :- findall( E, eccentricity(Tree, E, Leaf), Es  ),
	                           		          min_list(Es, LCurr),
					          LCurr < Curr, radii(Tree, Leaves, Radius, LCurr);
					          radii(Tree, Leaves, Radius, Curr).
radii(_, [], R, R).
radius_count( Tree, _, R ):- radius(Tree, R).
%Diameter = maximum eccentricity of any vertex.
diameter( Tree, D):- findall( E, (leaf(Tree, LeafNode), eccentricity(Tree, E, LeafNode)), Es ), 
		         max_list(Es, D ).
diameter_count(Tree, _, D):- diameter( Tree, D ).
\end{verbatim}

\subsubsection{Question 8}
Given a phylogeny P, a measure m, and a quantity q, determine all the
phylogenies that are at distance q from P according to the measure m (e.g., for
the purpose of clustering phylogenies that are "close" to a given tree);

This query has not been implemented. The basic frame-work developed for the other
size related queries will help with this, but supporting this query requires much
more extensive API documentation, and some analysis of the security implications
of accepting these from users.


\subsubsection{Question 9}
Given a model of evolution, determine all the phylogenies that have been
constructed using such model of evolution;


Not Implemented due to lack of complete data on phylogenies.  Not all
phylogenies say what model of evolution it used in its construction.

\subsubsection{Question 10}
Given some measures, return statistics about the measure in the phylogenies
present in the repository (e.g., distribution of tree lengths);


Not currently implemented but can be implemented using SPARQL.

\subsubsection{Question 11}
Given a type of data and a set of taxa, determine all the phylogenies on the
set of taxa that have been constructed using the specified type of data (e.g.,
determine all phylogenies built using morphological data or using DNA
sequences).	


This can be done with a combination of Question 1 and then using a SPARQL query
to filter/reduce that set based on the type of data requested.

\section{Results}

\subsection{Triple-Store}

Trees in the Triple-Store were taken from TreeBase as Nexus files, then
converted the files to RDF using our own program, then loaded up the RDF files
to our database.  Matrices can be downloaded as NeXML files from TreeBase, we
do not store them in our database just convert them when we needd to access
them.

\subsection{Prolog Storage}

The basic set up for the Prolog queries were described previously.  All the
ground rules were generated from the Triple-Store and converted into their
prolog form.  This is then loaded with the actual prolog query anytime it is
called.

\subsection{Timed Queries}

Queries were timed using the \emph{time} and \emph{curl} commands.  Since our
WebPortal uses cgi-bin we just call directly with a specific url instead of the
form to get a more accurate time.

In order to get a basic idea of how long each query took, we used various
computers from our Department Computer Lab and averaged them up.  Table 1 shows
the average times per query when using either PhyloWS or the Portals cgi-bin.
Some cases dont have both implemented however.

The lab contained 3 different levels of hardware, we tested each evenly.

they are:\begin{verbatim}
HP 	Linux (SuSE) 	4 GB 	Intel Core2 Quad (4 cores) (64bit) 	2.5 Ghz
HP 	Linux (SuSE) 	2 GB 	AMD Athlon X2 Dual (64 bit) 	       5200+
HP 	Linux (SuSE) 	8 GB 	Intel Core i7 860 	                 2.8 GHz
\end{verbatim}

\begin{tabular}{|c|c|c|}
\hline
        & PhlyoWS Time(s) & WebPortal Time(s) \\ \hline
Q1   &  N/A                &   2.65   \\ \hline
Q2   & N/A                 & N/A\\ \hline
Q3a &  2.06                      & 2.23 \\ \hline
Q3b &  1.06                      & 1.12 \\ \hline
Q4a   & N/A                       &7.01 \\ \hline
Q4b & N/A                &  7.20\\ \hline
Q5   &  37.68                      & 44.27\\ \hline
Q6   & N/A                       &6.13\\ \hline
Q7   &   *                     & *\\ \hline
\end{tabular}
\\
\\

Query 1: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/tu/html?tu=Ilex\_anomala\&tu=Ilex\_glabra}

Query 3a: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/node/html?qtype=msc\&tree=Tree3099\&node=Ilex\_anomala\&node=Ilex\_glabra}
\\
PhyloWS Query\\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/phylows/msc/Tree3099/Ilex\_anomala/Ilex\_glabra}

Query 3b: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/node/html?qtype=nca\&tree=Tree3099\&node=Ilex\_anomala\&node=Ilex\_glabra}
\\
PhyloWS Query\\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/phylows/nca/Tree3099/Ilex\_anomala/Ilex\_glabra}

Query 4a: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/algorithm/html?algorithm=parsimony}

Query 4b: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/software/html?software=paup}

Query 5: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/size/html?criterion=node\&direction=less\&size=25}
\\
PhyloWS Query\\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/phylows/size/node/less/25}

Query 6: WebPortal Query \\
{\tt http://www.cs.nmsu.edu/\~{}cdaostore/cgi-bin/author/html?last=Piel}

Query 7:  Special Case

Query 7 is a special case in that it has not been fully implemented into the
Web Service yet due to timing constraints.  Currently, any query for this in a
web service times out the browswer we run it in.  However, we ran this natively
with SWI-Prolog and got the following results.

\section{Related Work}

\subsection{TreeBase}
%%TAKEN FROM CDAO PAPER RELATED WORK

TreeBASE \cite{treebase} is a relational database that stores phylogenies (of
different nature), the associated alignments and character data used to derive
the phylogenies, and several types of meta-data (e.g., authors and citations).
The content of TreeBASE is community contributed and it is restricted to
results of published studies. TreeBASE occupies a unique role, in providing
access to both description of trees as well as corresponding generating data
matrices.  The spirit of TreeBASE is to enable retrieval of trees and data for
study comparison, combination, and for reuse. The relational nature of the
underlying repository enables a set of standard queries for accessing the
repository. The original TreeBASE provided six forms of access to the
repository- search by taxon, by author, by citation, by study accession number,
by matrix accession number, and by structure.  The newest release has expanded
the submission formats (adding nexml as one of the supported formats, along
with NEXUS), added support for the PhyloWS API, and connection to the
PhyloWidget visualization tool.

\section{Future Work}

Improving the speed on some queries and fully implementing others.  Work on
adding MIAPA qualities to the webportal and eventually to the queries as well.

\bibliographystyle{plain}
  \bibliography{bibfile}
\end{document}
